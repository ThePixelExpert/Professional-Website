---
phase: 05-deployment-reconfiguration
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - k8s/frontend/deployment.yaml
  - k8s/backend/service.yaml
  - k8s/backend/endpoints.yaml
  - k8s/ingress.yaml
autonomous: true

must_haves:
  truths:
    - "Frontend k8s Deployment has resource limits appropriate for Pi cluster (128Mi limit)"
    - "Backend Service+Endpoints route traffic to Proxmox VM IP 192.168.0.50"
    - "Traefik Ingress routes /api to backend-service and / to frontend-service"
    - "Frontend pods have liveness and readiness probes"
  artifacts:
    - path: "k8s/frontend/deployment.yaml"
      provides: "Frontend Deployment + Service for k3s cluster"
      contains: "readinessProbe"
    - path: "k8s/backend/service.yaml"
      provides: "Backend Service without selectors (external backend)"
      contains: "port: 3001"
    - path: "k8s/backend/endpoints.yaml"
      provides: "Manual Endpoints pointing to Proxmox VM"
      contains: "192.168.0.50"
    - path: "k8s/ingress.yaml"
      provides: "Traefik path-based routing for split architecture"
      contains: "pathType: Prefix"
  key_links:
    - from: "k8s/ingress.yaml"
      to: "k8s/backend/service.yaml"
      via: "service name reference"
      pattern: "backend-service"
    - from: "k8s/backend/service.yaml"
      to: "k8s/backend/endpoints.yaml"
      via: "matching metadata.name"
      pattern: "name: backend-service"
    - from: "k8s/backend/endpoints.yaml"
      to: "Proxmox VM"
      via: "IP address in subsets.addresses"
      pattern: "192.168.0.50"
    - from: "k8s/ingress.yaml"
      to: "k8s/frontend/deployment.yaml"
      via: "service name reference"
      pattern: "frontend-service"
---

<objective>
Create Kubernetes manifests for the split architecture: frontend pods on k3s, backend traffic routed to external Proxmox VM.

Purpose: The k3s cluster needs updated manifests that deploy ONLY the frontend (stateless) and route API traffic to the backend running on the Proxmox VM at 192.168.0.50. The existing k8s/backend/deployment.yaml deploys backend pods IN the cluster (which causes SD card wear). It must be replaced with a Service+Endpoints pattern that routes to the external VM. The existing frontend deployment needs resource limits tuned for Pi constraints and health probes added.

Output: Updated frontend deployment with health probes and Pi-appropriate resources, new backend Service+Endpoints pointing to VM, updated ingress for split routing.
</objective>

<execution_context>
@/home/logan/.claude/get-shit-done/workflows/execute-plan.md
@/home/logan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-deployment-reconfiguration/05-RESEARCH.md

@k8s/frontend/deployment.yaml
@k8s/backend/deployment.yaml
@k8s/ingress.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update frontend Deployment and create backend Service+Endpoints</name>
  <files>k8s/frontend/deployment.yaml, k8s/backend/service.yaml, k8s/backend/endpoints.yaml</files>
  <action>
**k8s/frontend/deployment.yaml** - Rewrite the existing file:

Deployment:
1. apiVersion: apps/v1, kind: Deployment
2. metadata: name frontend, namespace website, labels app: frontend
3. spec.replicas: 2 (not 3 - Pi cluster has limited RAM, start conservative)
4. strategy: RollingUpdate with maxSurge 1, maxUnavailable 0 (zero-downtime)
5. Container spec:
   - name: frontend
   - image: 192.168.0.40:5000/frontend:latest (will be overridden by deploy script)
   - imagePullPolicy: Always
   - containerPort: 80
   - resources: requests memory 64Mi cpu 50m, limits memory 128Mi cpu 100m (tuned DOWN from current 256Mi/200m to fit 4GB Pi nodes)
   - readinessProbe: httpGet path / port 80, initialDelaySeconds 5, periodSeconds 10
   - livenessProbe: httpGet path / port 80, initialDelaySeconds 15, periodSeconds 20
6. Add emptyDir volumes for nginx cache and run directories (required when running as non-root with readOnlyRootFilesystem):
   - volume "cache" -> mountPath /var/cache/nginx
   - volume "run" -> mountPath /var/run

Service (in same file, separated by ---):
1. apiVersion: v1, kind: Service
2. metadata: name frontend-service, namespace website
3. selector: app: frontend
4. ports: TCP port 80 targetPort 80
5. type: ClusterIP (NOT LoadBalancer - Traefik handles external access via Ingress)

**k8s/backend/service.yaml** - Create NEW file (replaces the old deployment.yaml concept):

Service WITHOUT selectors (external backend pattern):
1. apiVersion: v1, kind: Service
2. metadata: name backend-service, namespace website
3. spec.ports: TCP port 3001 targetPort 3001
4. NO selector field (this is intentional - manual Endpoints will be used)
5. Add comment: "# No selector - traffic routed to manual Endpoints (Proxmox VM)"

**k8s/backend/endpoints.yaml** - Create NEW file:

Manual Endpoints pointing to Proxmox VM:
1. apiVersion: v1, kind: Endpoints
2. metadata: name backend-service (MUST match Service name exactly), namespace website
3. subsets.addresses: ip 192.168.0.50 (Proxmox VM static IP)
4. subsets.ports: port 3001
5. Add comment: "# Points to Express backend on Proxmox VM (192.168.0.50)"
6. Add comment: "# Update IP if VM address changes"

Why NOT ExternalName: ExternalName requires DNS hostname, not IP addresses. The Proxmox VM has a static IP (192.168.0.50) but no DNS entry. Manual Endpoints work directly with IPs.
  </action>
  <verify>
Run `kubectl apply --dry-run=client -f k8s/frontend/deployment.yaml` to validate syntax. Run `kubectl apply --dry-run=client -f k8s/backend/service.yaml` and `kubectl apply --dry-run=client -f k8s/backend/endpoints.yaml` to validate. All should report "configured (dry run)" without errors. Verify that k8s/backend/service.yaml does NOT contain a "selector" field. Verify k8s/backend/endpoints.yaml contains "192.168.0.50".
  </verify>
  <done>Frontend Deployment has 2 replicas, Pi-appropriate resource limits, health probes, and ClusterIP Service. Backend has selector-less Service with matching manual Endpoints pointing to 192.168.0.50:3001.</done>
</task>

<task type="auto">
  <name>Task 2: Update Traefik Ingress for split architecture routing</name>
  <files>k8s/ingress.yaml</files>
  <action>
Update k8s/ingress.yaml to route traffic in the split architecture. The existing ingress already has the correct structure (separate API and frontend ingress resources with priorities), but needs review and potential updates.

Requirements:
1. Keep the two-Ingress pattern (edwards-api-ingress and edwards-frontend-ingress)
2. API Ingress:
   - name: edwards-api-ingress, namespace: website
   - annotation: traefik.ingress.kubernetes.io/router.priority: "2000" (higher = matches first)
   - ingressClassName: traefik
   - rules for both edwardstech.dev and www.edwardstech.dev
   - path: /api, pathType: Prefix -> backend-service:3001
3. Frontend Ingress:
   - name: edwards-frontend-ingress, namespace: website
   - annotation: traefik.ingress.kubernetes.io/router.priority: "1000" (lower = catch-all)
   - ingressClassName: traefik
   - rules for both edwardstech.dev and www.edwardstech.dev
   - path: /, pathType: Prefix -> frontend-service:80

The existing ingress.yaml already has this structure. Verify the backend-service port matches 3001 (the Service+Endpoints port) and frontend-service port matches 80. If the existing file is already correct, keep it as-is but ensure the comments explain the split architecture routing.

Add a comment at the top explaining: "# Split architecture routing: /api -> backend VM (via Service+Endpoints), / -> frontend pods"
  </action>
  <verify>
Run `kubectl apply --dry-run=client -f k8s/ingress.yaml` to validate syntax. Verify the file references backend-service:3001 and frontend-service:80. Verify both edwardstech.dev and www.edwardstech.dev hosts are covered.
  </verify>
  <done>Ingress routes /api to backend-service:3001 (which routes to VM via Endpoints) and / to frontend-service:80 (which routes to frontend pods). Both domain variants covered.</done>
</task>

</tasks>

<verification>
1. `kubectl apply --dry-run=client -f k8s/frontend/deployment.yaml` succeeds
2. `kubectl apply --dry-run=client -f k8s/backend/service.yaml` succeeds
3. `kubectl apply --dry-run=client -f k8s/backend/endpoints.yaml` succeeds
4. `kubectl apply --dry-run=client -f k8s/ingress.yaml` succeeds
5. Backend service has NO selector field
6. Backend endpoints contain 192.168.0.50
7. Frontend replicas = 2, memory limit = 128Mi
8. Frontend has readiness and liveness probes
9. Ingress routes /api -> backend-service:3001, / -> frontend-service:80
</verification>

<success_criteria>
- All k8s manifests pass dry-run validation
- Frontend pods will have health probes and Pi-appropriate resource limits
- Backend traffic routes from k3s cluster to Proxmox VM via Service+Endpoints
- Traefik ingress splits /api and / traffic to correct services
- No backend pods or database StatefulSets will be deployed to k3s
</success_criteria>

<output>
After completion, create `.planning/phases/05-deployment-reconfiguration/05-03-SUMMARY.md`
</output>
