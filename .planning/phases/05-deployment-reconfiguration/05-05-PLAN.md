---
phase: 05-deployment-reconfiguration
plan: 05
type: execute
wave: 3
depends_on: ["05-03", "05-04"]
files_modified:
  - k8s/database/postgres-deployment.yaml
  - k8s/backend/deployment.yaml
  - k8s/backend/deployment-secure.yaml
  - k8s/backend/secret.yaml
autonomous: false

must_haves:
  truths:
    - "Old k8s backend deployment manifest is archived, not active"
    - "Old k8s postgres StatefulSet manifest is archived, not active"
    - "Pi cluster has no stateful workloads after applying new manifests"
    - "Split architecture documentation explains the deployment topology"
  artifacts:
    - path: "k8s/legacy/backend-deployment.yaml"
      provides: "Archived old backend k8s deployment"
      contains: "ARCHIVED"
    - path: "k8s/legacy/postgres-deployment.yaml"
      provides: "Archived old postgres k8s StatefulSet"
      contains: "ARCHIVED"
  key_links:
    - from: "k8s/backend/service.yaml"
      to: "k8s/backend/endpoints.yaml"
      via: "Replaces old backend deployment with external routing"
      pattern: "backend-service"
---

<objective>
Archive old k8s manifests for backend and database that are no longer needed in the split architecture, and verify the complete deployment configuration.

Purpose: The split architecture moves backend and database OFF the Pi cluster. The old k8s/backend/deployment.yaml (which deploys backend pods to k3s) and k8s/database/postgres-deployment.yaml (which runs PostgreSQL on Pi SD cards) must be archived - not deleted, in case rollback is needed. This plan also includes a human verification checkpoint to review the complete configuration before any actual deployment.

Output: Archived legacy manifests, clean k8s directory structure, verification checkpoint.
</objective>

<execution_context>
@/home/logan/.claude/get-shit-done/workflows/execute-plan.md
@/home/logan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-deployment-reconfiguration/05-RESEARCH.md

@k8s/backend/deployment.yaml
@k8s/backend/deployment-secure.yaml
@k8s/backend/secret.yaml
@k8s/database/postgres-deployment.yaml
@k8s/frontend/deployment.yaml
@k8s/backend/service.yaml
@k8s/backend/endpoints.yaml
@k8s/ingress.yaml
@Dockerfile.backend
@Dockerfile.frontend
@docker-compose.backend.yml
@nginx.conf
@scripts/build-and-push.sh
@scripts/deploy-backend.sh
@scripts/deploy-k8s.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Archive legacy k8s manifests and clean up directory structure</name>
  <files>k8s/legacy/backend-deployment.yaml, k8s/legacy/backend-deployment-secure.yaml, k8s/legacy/backend-secret.yaml, k8s/legacy/postgres-deployment.yaml, k8s/legacy/cert-manager.yaml</files>
  <action>
Move old k8s manifests that are no longer needed in the split architecture to a k8s/legacy/ directory. These are kept for reference/rollback, not for active use.

Steps:
1. Create k8s/legacy/ directory
2. Move k8s/backend/deployment.yaml -> k8s/legacy/backend-deployment.yaml
3. Move k8s/backend/deployment-secure.yaml -> k8s/legacy/backend-deployment-secure.yaml
4. Move k8s/backend/secret.yaml -> k8s/legacy/backend-secret.yaml
5. Move k8s/database/postgres-deployment.yaml -> k8s/legacy/postgres-deployment.yaml
6. Move k8s/cert-manager.yaml -> k8s/legacy/cert-manager.yaml (cert-manager was for the old setup; Traefik handles certs now)
7. Add a comment header to each archived file: "# ARCHIVED: Replaced by split architecture (Phase 5). Backend now runs on Proxmox VM."
8. Remove the now-empty k8s/database/ directory

After cleanup, the k8s/ directory should look like:
```
k8s/
  frontend/
    deployment.yaml    (updated in Plan 03)
  backend/
    service.yaml       (new - created in Plan 03)
    endpoints.yaml     (new - created in Plan 03)
  ingress.yaml         (updated in Plan 03)
  legacy/              (archived old manifests)
    backend-deployment.yaml
    backend-deployment-secure.yaml
    backend-secret.yaml
    postgres-deployment.yaml
    cert-manager.yaml
```

Use git mv for the moves so git tracks the file history.
  </action>
  <verify>
Run `ls -R k8s/` to verify the directory structure matches expected layout. Verify k8s/backend/ contains ONLY service.yaml and endpoints.yaml (no deployment.yaml). Verify k8s/database/ directory no longer exists. Verify k8s/legacy/ contains all 5 archived files.
  </verify>
  <done>Legacy manifests archived in k8s/legacy/, active k8s/ directory contains only split-architecture manifests, no database or backend deployment manifests in active paths.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Review complete split architecture configuration</name>
  <what-built>
Complete split architecture deployment configuration:

**Backend (Proxmox VM - 192.168.0.50):**
- Dockerfile.backend (updated with health check + src/ directory)
- docker-compose.backend.yml (binds 0.0.0.0:3001, env_file, health check)
- contact-backend/.env.production.template (Supabase-era env vars)

**Frontend (Pi k3s cluster - 192.168.0.40-43):**
- Dockerfile.frontend (multi-stage, non-root, health check, build args)
- nginx.conf (static only, no API proxy)
- k8s/frontend/deployment.yaml (2 replicas, 128Mi limit, health probes)

**Routing (Traefik on k3s):**
- k8s/backend/service.yaml + endpoints.yaml (routes to VM IP)
- k8s/ingress.yaml (/api -> VM, / -> frontend pods)

**Scripts:**
- scripts/build-and-push.sh (arm64 frontend, amd64 backend)
- scripts/deploy-backend.sh (SSH to VM, docker compose up)
- scripts/deploy-k8s.sh (kubectl apply manifests)

**Archived:**
- k8s/legacy/ (old backend deployment, postgres StatefulSet, etc.)
  </what-built>
  <how-to-verify>
Review the following files and confirm the configuration looks correct for your infrastructure:

1. Check Dockerfile.backend copies all src/ files:
   `grep -n "COPY" Dockerfile.backend`

2. Check nginx.conf has NO API proxying:
   `grep -n "proxy_pass\|backend-service" nginx.conf` (should return nothing)

3. Check backend endpoints point to correct VM IP:
   `grep "ip:" k8s/backend/endpoints.yaml`

4. Check frontend resource limits are appropriate for your Pis:
   `grep -A2 "limits:" k8s/frontend/deployment.yaml`

5. Check ingress routes:
   `grep -B2 -A3 "backend-service\|frontend-service" k8s/ingress.yaml`

6. Check build script platforms:
   `grep "platform" scripts/build-and-push.sh`

7. Verify k8s/legacy/ contains archived files:
   `ls k8s/legacy/`
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 5, or describe any issues to address.</resume-signal>
</task>

</tasks>

<verification>
1. k8s/ directory structure has clean separation: active manifests and legacy/ archive
2. No backend Deployment or database StatefulSet in active k8s paths
3. All prior plan outputs (01-04) are present and consistent
4. Human has reviewed and approved the complete configuration
</verification>

<success_criteria>
- Legacy manifests archived (not deleted) for rollback capability
- Clean k8s directory with only split-architecture manifests active
- Human has verified the complete deployment topology is correct
- Phase 5 ready for actual deployment when infrastructure is available
</success_criteria>

<output>
After completion, create `.planning/phases/05-deployment-reconfiguration/05-05-SUMMARY.md`
</output>
