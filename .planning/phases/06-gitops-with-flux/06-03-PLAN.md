---
phase: 06-gitops-with-flux
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - flux/clusters/production/backend/kustomization.yaml
  - flux/clusters/production/backend/deploy-job.yaml
  - flux/clusters/production/backend/docker-compose.backend.yml
autonomous: true

must_haves:
  truths:
    - "Backend deployment is triggered via a Kubernetes Job that SSHs to the Proxmox VM"
    - "docker-compose.backend.yml contains Flux image setter comment for automated tag updates"
    - "Backend deploy Job uses sealed SSH key and runs git pull + docker compose up on the VM"
  artifacts:
    - path: "flux/clusters/production/backend/deploy-job.yaml"
      provides: "Kubernetes Job that SSHs to VM to deploy backend"
      contains: "ssh.*192.168.0.50"
    - path: "flux/clusters/production/backend/docker-compose.backend.yml"
      provides: "Docker Compose for backend with Flux setter comment"
      contains: "imagepolicy"
    - path: "flux/clusters/production/backend/kustomization.yaml"
      provides: "Kustomize config for backend resources"
      contains: "resources:"
  key_links:
    - from: "flux/clusters/production/backend/deploy-job.yaml"
      to: "192.168.0.50"
      via: "SSH connection to Proxmox VM"
      pattern: "192\\.168\\.0\\.50"
    - from: "flux/clusters/production/backend/docker-compose.backend.yml"
      to: "flux-system:backend"
      via: "Flux image setter comment"
      pattern: 'imagepolicy.*flux-system:backend'
---

<objective>
Create Flux-managed backend deployment manifests: a Kubernetes Job that SSHs to the Proxmox VM and a docker-compose file with Flux setter comment.

Purpose: The backend runs on a Proxmox VM (not in k3s), so Flux cannot directly manage it as a Kubernetes Deployment. Instead, Flux manages a Kubernetes Job that bridges the gap: when Flux reconciles, the Job SSHs to the VM, pulls the latest code (which includes the updated docker-compose.backend.yml with new image tag), and runs docker compose up. The docker-compose file gets its image tag updated by Flux ImageUpdateAutomation via setter comments, same as the frontend deployment.

Output: Backend Kustomize overlay with deploy Job and docker-compose file containing Flux setter comment.
</objective>

<execution_context>
@/home/logan/.claude/get-shit-done/workflows/execute-plan.md
@/home/logan/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-gitops-with-flux/06-RESEARCH.md
@docker-compose.backend.yml
@scripts/deploy-backend.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backend docker-compose with Flux setter comment</name>
  <files>flux/clusters/production/backend/docker-compose.backend.yml</files>
  <action>
    Create `flux/clusters/production/backend/docker-compose.backend.yml` based on the root docker-compose.backend.yml but with a Flux image setter comment.

    This is the Flux-managed version. Flux ImageUpdateAutomation will write new image tags to this file when new backend images appear in Harbor.

    ```yaml
    version: '3.8'

    services:
      backend:
        image: 192.168.0.40:5000/backend:main-placeholder-0000000000 # {"$imagepolicy": "flux-system:backend"}
        container_name: edwards-backend
        restart: unless-stopped
        env_file: .env
        ports:
          - "0.0.0.0:3001:3001"
        healthcheck:
          test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3001/api/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})\""]
          interval: 30s
          timeout: 3s
          retries: 3
          start_period: 40s
        logging:
          driver: json-file
          options:
            max-size: "10m"
            max-file: "3"
        deploy:
          resources:
            limits:
              cpus: '2'
              memory: 512M
            reservations:
              cpus: '0.5'
              memory: 256M
    ```

    CRITICAL changes from root docker-compose.backend.yml:
    - Image tag changed from `${GIT_SHA:-latest}` to `main-placeholder-0000000000` (hardcoded, not env var) with the Flux setter comment
    - The setter comment `# {"$imagepolicy": "flux-system:backend"}` MUST be on the same line as the image value
    - No `${GIT_SHA}` variable substitution - Flux writes the actual tag directly into the file

    The root docker-compose.backend.yml stays as-is for manual deployments. This Flux-managed copy is what gets deployed to the VM via the Job.
  </action>
  <verify>
    Verify file exists: `ls flux/clusters/production/backend/docker-compose.backend.yml`
    Verify setter comment: `grep 'imagepolicy' flux/clusters/production/backend/docker-compose.backend.yml`
    Verify no env var in image: `grep -c 'GIT_SHA' flux/clusters/production/backend/docker-compose.backend.yml` should be 0
    Validate YAML: `python3 -c "import yaml; yaml.safe_load(open('flux/clusters/production/backend/docker-compose.backend.yml'))"`
  </verify>
  <done>
    Flux-managed docker-compose.backend.yml exists with hardcoded image tag and Flux setter comment. No environment variable substitution in image field.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create backend deploy Job and Kustomization</name>
  <files>
    flux/clusters/production/backend/deploy-job.yaml
    flux/clusters/production/backend/kustomization.yaml
  </files>
  <action>
    1. **flux/clusters/production/backend/deploy-job.yaml:**

    Create a Kubernetes Job that SSHs to the Proxmox VM and deploys the backend:

    ```yaml
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: backend-deploy
      namespace: website
    spec:
      backoffLimit: 1
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: deployer
            image: alpine:3.19
            command:
            - /bin/sh
            - -c
            - |
              set -e
              # Install SSH client
              apk add --no-cache openssh-client

              # Configure SSH key
              mkdir -p /root/.ssh
              cp /keys/id_ed25519 /root/.ssh/id_ed25519
              chmod 600 /root/.ssh/id_ed25519

              SSH_OPTS="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o LogLevel=ERROR"
              VM_HOST="ubuntu@192.168.0.50"
              DEPLOY_DIR="/opt/backend"

              echo "=== Backend Deployment to VM ==="

              # Ensure deploy directory exists
              ssh $SSH_OPTS $VM_HOST "mkdir -p ${DEPLOY_DIR}"

              # Copy the Flux-managed docker-compose file from git repo on VM
              # The VM has the repo cloned; we pull latest which includes Flux's tag update
              ssh $SSH_OPTS $VM_HOST "cd /opt/professional-website && git pull origin master"

              # Copy the Flux-managed compose file to the deploy directory
              ssh $SSH_OPTS $VM_HOST "cp /opt/professional-website/flux/clusters/production/backend/docker-compose.backend.yml ${DEPLOY_DIR}/docker-compose.yml"

              # Pull the new image and restart
              ssh $SSH_OPTS $VM_HOST "cd ${DEPLOY_DIR} && docker compose pull && docker compose up -d"

              # Wait for health check
              echo "Waiting for backend health check..."
              sleep 10
              ssh $SSH_OPTS $VM_HOST "curl -sf http://localhost:3001/api/health" || {
                echo "ERROR: Backend health check failed!"
                ssh $SSH_OPTS $VM_HOST "cd ${DEPLOY_DIR} && docker compose logs --tail=30"
                exit 1
              }

              echo "Backend deployment successful!"
            volumeMounts:
            - name: ssh-key
              mountPath: /keys
              readOnly: true
          volumes:
          - name: ssh-key
            secret:
              secretName: vm-ssh-key
              defaultMode: 0400
    ```

    Key design decisions:
    - Uses `alpine:3.19` (small image, installs openssh-client at runtime). Alpine has confirmed ARM64 support for Pi cluster.
    - SSH key mounted from Sealed Secret `vm-ssh-key` with mode 0400 (SSH refuses keys with loose permissions)
    - `StrictHostKeyChecking=no` because the VM does not have a DNS entry, just an IP
    - `backoffLimit: 1` - retry once on failure, then mark Job as failed
    - `restartPolicy: Never` - Job runs once per Flux reconciliation
    - Health check after deployment validates the backend started correctly
    - The VM has the git repo cloned at `/opt/professional-website`. The Job does `git pull` to get the latest docker-compose file (with Flux's updated tag), copies it to the deploy dir, and runs docker compose.

    2. **flux/clusters/production/backend/kustomization.yaml:**
    ```yaml
    apiVersion: kustomize.config.k8s.io/v1beta1
    kind: Kustomization
    resources:
      - deploy-job.yaml
    ```

    Note: docker-compose.backend.yml is NOT listed in kustomization resources - it is a Docker Compose file, not a Kubernetes resource. It lives in this directory so Flux ImageUpdateAutomation can update its setter comment, but it is applied to the VM via SSH in the Job, not via kubectl.
  </action>
  <verify>
    Verify files exist: `ls flux/clusters/production/backend/`
    Verify SSH target: `grep '192.168.0.50' flux/clusters/production/backend/deploy-job.yaml`
    Verify secret mount: `grep 'vm-ssh-key' flux/clusters/production/backend/deploy-job.yaml`
    Verify health check: `grep 'api/health' flux/clusters/production/backend/deploy-job.yaml`
    Verify kustomization: `grep 'deploy-job.yaml' flux/clusters/production/backend/kustomization.yaml`
    Validate YAML: `python3 -c "import yaml; [yaml.safe_load(open(f)) for f in ['flux/clusters/production/backend/deploy-job.yaml', 'flux/clusters/production/backend/kustomization.yaml']]"`
  </verify>
  <done>
    Backend deploy Job SSHs to 192.168.0.50, pulls latest git repo (with Flux-updated docker-compose), copies compose file to deploy dir, runs docker compose pull/up, and verifies health. Kustomization references the Job. Docker-compose file with setter comment lives alongside for Flux to update.
  </done>
</task>

</tasks>

<verification>
- `ls flux/clusters/production/backend/` shows 3 files (kustomization, deploy-job, docker-compose)
- docker-compose has Flux setter comment and no env var in image tag
- Deploy Job mounts SSH key, targets 192.168.0.50, runs health check
- Kustomization only references deploy-job.yaml (not docker-compose)
- All YAML files parse without errors
</verification>

<success_criteria>
- Backend deploy Job exists and targets Proxmox VM via SSH
- docker-compose.backend.yml has Flux setter comment for image automation
- Job includes health check validation after deployment
- Kustomize structure is correct (only k8s resources in kustomization)
</success_criteria>

<output>
After completion, create `.planning/phases/06-gitops-with-flux/06-03-SUMMARY.md`
</output>
